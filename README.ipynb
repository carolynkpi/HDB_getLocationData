{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# README: Get Location Data\n",
    "The code here is part of Phase 2 of the Singapore HDB Resale Prices project: <https://carolynkpi.shinyapps.io/app_hdb/>. \n",
    "\n",
    "The code gets location data for each HDB block. The data includes:\n",
    "\n",
    "1. Nearest MRT/LRT station\n",
    "2. Radial distance to nearest MRT station. \n",
    "3. Walking distance to nearest MRT station. \n",
    "4. Number of MRT/LRT stations nearby.\n",
    "5. Number of bus stations nearby.\n",
    "6. Number of schools nearby.\n",
    "7. Number of food places nearby. \n",
    "8. Number of shopping places nearby. \n",
    "\n",
    "I am using 3 Google APIs. Each API requires a separate key.  \n",
    "\n",
    "1. Google Maps Geocoding (Location data 1)\n",
    "2. Google Maps Distance Matrix (Location data 3)\n",
    "3. Google Places (Location data 4 -8)\n",
    "\n",
    "While I really **love** Google because it is **free**, there is a daily usage limit on each API.  \n",
    "\n",
    "1. Google Maps Geocoding - 2500 requests per day, 50 requests per second\n",
    "2. Google Maps Distance Matrix - 2500 elements per day, 100 elements per second. \n",
    "3. Google Places - 1000 request per day by default, upgradable to 150,000 elements per day for free but with billing enablement. \n",
    "\n",
    "With this constraint, the codes are designed to: \n",
    "- be run for several times across several days (to keep within usage limits)\n",
    "- save each data point as it is retrieved (so that returned data points are not lost if the code stops unexpectedly)\n",
    "- log failed requests separately for retrying later (to make sure retries do not burst the usage limits)  \n",
    "\n",
    "The entire project takes 2 input files: ***resale_prices_2015_.csv*** and ***mrt.csv***.\n",
    "\n",
    "While the project is done mostly in R, this data acquisition via API is done using Python. \n",
    "There is no special reason for that, just for my convenience because of my familiarity with Python when it comes to API. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import json as json\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review Data\n",
    "Let us first review our HDB data [Source: <https://data.gov.sg/dataset/resale-flat-prices>]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     month        town flat_type block        street_name storey_range  \\\n",
      "0  2015-01  ANG MO KIO    3 ROOM   174   ANG MO KIO AVE 4     07 TO 09   \n",
      "1  2015-01  ANG MO KIO    3 ROOM   541  ANG MO KIO AVE 10     01 TO 03   \n",
      "2  2015-01  ANG MO KIO    3 ROOM   163   ANG MO KIO AVE 4     01 TO 03   \n",
      "3  2015-01  ANG MO KIO    3 ROOM   446  ANG MO KIO AVE 10     01 TO 03   \n",
      "4  2015-01  ANG MO KIO    3 ROOM   557  ANG MO KIO AVE 10     07 TO 09   \n",
      "\n",
      "   floor_area_sqm      flat_model  lease_commence_date  remaining_lease  \\\n",
      "0            60.0        Improved                 1986               70   \n",
      "1            68.0  New Generation                 1981               65   \n",
      "2            69.0  New Generation                 1980               64   \n",
      "3            68.0  New Generation                 1979               63   \n",
      "4            68.0  New Generation                 1980               64   \n",
      "\n",
      "   resale_price  \n",
      "0      255000.0  \n",
      "1      275000.0  \n",
      "2      285000.0  \n",
      "3      290000.0  \n",
      "4      290000.0   \n",
      "\n",
      "Number of data points:  55979\n",
      "Number of unique data points: 8260\n"
     ]
    }
   ],
   "source": [
    "dataFile = 'resale_prices_2015_.csv'\n",
    "raw = pd.read_csv(dataFile)\n",
    "print(raw.head(), '\\n')\n",
    "address = 'Blk ' + raw['block'] + ' ' + raw['street_name'] \n",
    "print('Number of data points: ', len(address))\n",
    "print('Number of unique data points:', len(address.unique()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To be eliminate redundancies in the API requests, each address (i.e. each HDB block) should only be queried once for each type of requests. \n",
    "\n",
    "Now let us look at the list of Singapore MRT/LRT stations [Source:<https://en.wikipedia.org/wiki/List_of_Singapore_MRT_stations> ]. The data is obtained from but Wikipedia, but I have done some manual editing to the data using Excel. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Station Code Station Name  Planning Area      Region     NS     EW     CG  \\\n",
      "0         NS10    Admiralty      Woodlands       NORTH   True  False  False   \n",
      "1          EW9     Aljunied        Geylang     CENTRAL  False   True  False   \n",
      "2         NS16   Ang Mo Kio     Ang Mo Kio  NORTH-EAST   True  False  False   \n",
      "3          SE3        Bakau       Sengkang  NORTH-EAST  False  False  False   \n",
      "4          BP9      Bangkit  Bukit Panjang        WEST  False  False  False   \n",
      "\n",
      "      NE  BP LRT  Sengkang LRT                 ...                  Line 2  \\\n",
      "0  False   False         False                 ...                     NaN   \n",
      "1  False   False         False                 ...                     NaN   \n",
      "2  False   False         False                 ...                     NaN   \n",
      "3  False   False          True                 ...                     NaN   \n",
      "4  False    True         False                 ...                     NaN   \n",
      "\n",
      "   Line 3  Opening 1  Opening 2 Opening 3  Bus Interchange  Bus Terminal  \\\n",
      "0     NaN  10/2/1996        NaN       NaN            False         False   \n",
      "1     NaN  4/11/1989        NaN       NaN            False         False   \n",
      "2     NaN  7/11/1987        NaN       NaN             True         False   \n",
      "3     NaN  18/1/2003        NaN       NaN            False         False   \n",
      "4     NaN  6/11/1999        NaN       NaN            False         False   \n",
      "\n",
      "  Others Connections to Other Connection to other transport means  \n",
      "0  False                    0                                 NaN  \n",
      "1  False                    0                                 NaN  \n",
      "2  False                    1         Â Ang Mo Kio Bus Interchange  \n",
      "3  False                    0                                 NaN  \n",
      "4  False                    0                                 NaN  \n",
      "\n",
      "[5 rows x 28 columns] \n",
      "\n",
      "Number of MRT/LRT stations:  190\n"
     ]
    }
   ],
   "source": [
    "mrtFile = 'MRT.csv'\n",
    "mrt = pd.read_csv(mrtFile)\n",
    "print(mrt.head(), '\\n')\n",
    "print('Number of MRT/LRT stations: ', len(mrt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Acquisition Strategy\n",
    "\n",
    "There are 6 steps in this data acquisition, as described below.  \n",
    "1. Using Google Maps Geocoding API, get the coordinates for (a) each MRT station and (b) each HDB block.\n",
    "2. Calculate the radial distance from each HDB block to each MRT station. \n",
    "3. Find the nearest MRT/LRT station to each HDB block by finding the minimal radial distance. \n",
    "4. Using Google Maps Distance Matrix API, get the walking distance from each HDB block to the nearest MRT/LRT station found in Step 3. \n",
    "5. Using Google Places API, get the places nearby each HDB block. \n",
    "6. Integrated data retrieved from previous steps to produced one final output csv file.   \n",
    "\n",
    "Finding the nearest MRT/LRT station and the distance is a little tricky. A naive way is to use the Google Maps Distance Matrix to get the walking distance from every HDB block to every MRT station.  But that will result in 8260 HDB x 190 stations = 1,569,400 request. Given the free usage limit, these requests will require 628 days = 1.7 years to complete! To work around this problem, I have devised Steps 1-4. This will mean that the nearest MRT is defined by radial distance, but a walking distance to that nearest MRT is also provided. \n",
    "\n",
    "To complete location data acquisition, I took approximately 2 weeks. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Codes\n",
    "The codes are written in a modular approach, i.e. the codes can be run separately and the results can be saved progressively.  This is to minimize repeat runs as the process is computationally expensive. \n",
    "\n",
    "Besides the codes for each of Steps 1 - 6, there are 3 other files required as described below: \n",
    "\n",
    "1. **myFunctions.py**: <link for myFunctions>. This file contains all the common functions necessary to query Google's API including tryGET, tryGETp, getParamString and getKeys. \n",
    "\n",
    "2. **placesTracker.py**: <link for placesTracker>. This file enforces a tracker that will track the usage of the Google Places API. This is because there is billing enabled to the Places API and I just wanted to make sure that I don't accidentally exceed the free 150,000 requests limit. But it turns out that wasn't necessary since the requests ended up being limited by the inter-query sleep time. This file is imported to myFunctions.py. It relies on a log file residing in the same project directory called ***'PlacesTracker.txt'***.  I have included a ***'PlacesTracker - Master.txt'*** file to start off a new project. \n",
    "\n",
    "3. **Combine_Files.ipynb**: Because some steps can be split to several separate runs, this file is used to combine their outputs. <br>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
